{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7409aaab-75c8-4191-9073-44c65f7794fc",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8d717-cfe3-4423-9b4d-08ab3930b97f",
   "metadata": {},
   "source": [
    "Пояснения к коду написаны в формате докстрингов, комментариев и Markdown.\n",
    "\n",
    "Я нормально не тестировал функции, поэтому нижеследующее -- это скорее текст по проделанному резерчу. Хотя код писался из практических соображений.\n",
    "\n",
    "В каком-то месте я мог по невнимательности забыть умножить флопсы на число слоев или перевести параметры в число байт, и скорее всего где-то забыл."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb2e1d-8fbb-4be1-9383-13e7e6eb9ba9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b436ce2-5294-4a1c-bffc-3683b510bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from typing import Tuple, Optional, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97549f45-20ce-4e8e-99d7-a1a5bf24a4d4",
   "metadata": {},
   "source": [
    "## Specs of Models with Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98ef5e-0cc3-42d8-95f6-e8dc1ae66588",
   "metadata": {},
   "source": [
    "Basic specs (e.g. hidden_dim) were mostly taken from orginal papers. Rarely taken from huggingface implementation (e.g. LLaMA feed_forward_dim).\n",
    "\n",
    "#### LLaMA\n",
    "Compared to naive decoder there are no architectual changes of substantial importanse for us, see e.g. https://paperswithcode.com/method/llama.\n",
    "Activation functions, Rotary Embeddings and Normalizations are computationaly negligible.\n",
    "Although some of them might introduce slight memory footprint or FLOPs expantion depending on their implementation \n",
    "(e.g. SILU and SwiGLU activations, (x2)), it does not change the bigger picture as will be discussed later.\n",
    "#### LLaMA2\n",
    "I hope I am not wrong about this, but the only relevant thing seems to be grouped-query attention.\n",
    "#### Mistral \n",
    "Mistral is a bit different. It uses sliding window attention and grouped-query attention, has different hyperparams and some hacks that are not relevant to us at the moment.\n",
    "#### Mixtral\n",
    "Mixtral is like Mistral, but with MoE and without a paper. \n",
    "Basically, during inference FF layers double for each token (in a parallel manner) and a small routing layer is added in front of FF.\n",
    "Also 8 FFs need to be kept in VRAM for eash layer instead of 1. \n",
    "This results in a significant memory footprint since FFs take the most of Mistral parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d03e2f-6d1c-49f9-80ae-3a89fc73fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_2_byte_factor = {\n",
    "    'fp32': 4, \n",
    "    'fp16': 2, \n",
    "    'int8': 1, \n",
    "    'int4': 0.5,\n",
    "  }\n",
    "\n",
    "specs = {\n",
    "  'LLaMA': {\n",
    "    'params': 6.7e9,\n",
    "    'dim': 4096, \n",
    "    'feed_forward_dim': 11008, \n",
    "    'n_heads': 32,\n",
    "    'n_kv_heads': 32, \n",
    "    # in a context of grouped-query attention\n",
    "    'n_layers': 32,\n",
    "    'max_tokens': 2048, \n",
    "    # Since the model was not trained on longer sequences, exceeding that might lead to poor performance. \n",
    "    # That will not be allowed to piss everyone off.\n",
    "    'sliding_window': np.inf,\n",
    "  },\n",
    "  'LLaMA2': {\n",
    "    'params': 6.7e9,\n",
    "    'dim': 4096, \n",
    "    'feed_forward_dim': 11008, \n",
    "    'n_heads': 32,\n",
    "    'n_kv_heads': 8,\n",
    "    'n_layers': 32,\n",
    "    'max_tokens': 4096,\n",
    "    'sliding_window': np.inf,\n",
    "  },\n",
    "  'Mistral': {\n",
    "    'params': 7.3e9,\n",
    "    'dim': 4096, \n",
    "    'feed_forward_dim': 14336, \n",
    "    'n_heads': 32,\n",
    "    'n_kv_heads': 8,\n",
    "    'n_layers': 32,\n",
    "    'max_tokens': 131072, # They say 8k works fine. 131072 is just a context length.\n",
    "    'sliding_window': 4096,\n",
    "  },\n",
    "  'Mixtral': {\n",
    "    'params': 46.7e9,\n",
    "    'dim': 4096, \n",
    "    'feed_forward_dim': 14336, \n",
    "    'n_heads': 32,\n",
    "    'n_kv_heads': 8,\n",
    "    'n_layers': 32,\n",
    "    'max_tokens': 131072, # They say 32k works fine. 131072 is just a context length.\n",
    "    'sliding_window': 4096,\n",
    "  } # number of experts is hardcoded to 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399980e-8b9c-4ae9-98c2-1d53a1d49d55",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32da11-4830-4900-ae0e-5ba09bfdcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_length(gpu_mem: int, model_arch: str, model_format: str, KV_cache_format: str):\n",
    "  \"\"\"\n",
    "  Calculates theoretical max context+output length under the given constraints.\n",
    "  Assumptions: \n",
    "   - only one GPU is used\n",
    "   - batch size = 1\n",
    "   - max context length is calculated for the smallest available model version of a corresponding architecture, \n",
    "   as it have not been stated explicitly how to handle this aspect. I believe it is not a substantial aspect, \n",
    "   although a tedious one.\n",
    "  \n",
    "  Args:\n",
    "    gpu_mem: Available GPU Global Memory in bytes\n",
    "    model_arch: one of ['LLaMA', 'LLaMA2', 'Mistral', 'Mixtral']\n",
    "    model_format: one of ['fp32', 'fp16', 'int8', 'int4']\n",
    "    KV_cache_format: a format of previous key value cache, one of ['fp32', 'fp16', 'int8']\n",
    "\n",
    "  Returns:\n",
    "    Max number of context tokens+1 (under the most sensible and favourable setup that meets all the input \n",
    "    constraints). Or max context+output length in other words.\n",
    "\n",
    "  So here is what I think.\n",
    "  1) We will use cache and never recalculate attention for the same token, based on task formulation.\n",
    "  2) For memory efficiency purposes context will be treated the same way as generated content -- with multiple \n",
    "  forward passes.\n",
    "  In some cases, it might significantly slow us down (as when model generates only one token), \n",
    "  but memory footprint reduction might be worth it, especially with low KV_cache_format.\n",
    "  See the next task for an alternative approach on context processing.\n",
    "  3) We will not use CPU offloading since it conceptually undermines our mission.\n",
    "  \"\"\"\n",
    "\n",
    "  # We could binsearch for a right number of tokens, but I will keep it simple, assuming it can't be bigger than 1000k.\n",
    "  if can_fit_n(1000000, gpu_mem, model_arch, model_format, KV_cache_format):\n",
    "    print('seems like it can feet anything beyond reasonable, we can\\'t handle that')\n",
    "    return -1\n",
    "    \n",
    "  for n in range(1000000):\n",
    "    if not can_fit_n(n, gpu_mem, model_arch, model_format, KV_cache_format):\n",
    "      return n\n",
    "      \n",
    "\n",
    "def can_fit_n(n: int, gpu_mem: int, model_arch: str, model_format: str, KV_cache_format: str):\n",
    "  \"\"\"\n",
    "  Checks whether calc_max_length(...) >= n. For more see calc_max_length().\n",
    "\n",
    "  Returns:\n",
    "    bool: whether n tokens can be processed to generate one\n",
    "  \"\"\"\n",
    "\n",
    "  spec = specs[model_arch]\n",
    "  \n",
    "  if n > spec['max_tokens']:\n",
    "    return False\n",
    "\n",
    "  # bytes to store kv cache\n",
    "  kv_cash_mem = 2 * min(spec['sliding_window'], n-1) * format_2_byte_factor[KV_cache_format] * spec['n_kv_heads'] * \\\n",
    "                (spec['dim'] / spec['n_heads']) * spec['n_layers']\n",
    "  \n",
    "  # memory to store intermediate activations of FeedForward, as feed_forward_dim >= dim always\n",
    "  # As always, I suppose that SwiGLU (llama1,2) or SILU (Mistral, Mixtral) activations are implemented in such a way\n",
    "  # that does not require extra memory in global gpu memory storage. Otherwise FF_mem should be multiplied by 2.\n",
    "  FF_bottleneck_mem = (spec['feed_forward_dim'] + spec['dim']) * \\\n",
    "                      format_2_byte_factor[model_format] # spec['dim'] for residual connection\n",
    "  if model_arch == 'Mixtral':\n",
    "    FF_bottleneck_mem *= 2 # since we use 2 experts; gated layer is small\n",
    "\n",
    "  # current attention layer extra memory. We probably compute k,v,q for 1 token simultaneously,\n",
    "  # and then send our query to SM's local memory to compute dot products.\n",
    "  # Since this query duplication does not affect the global memory, we should not worry.\n",
    "  # And k,v are just cached. Cache for all layers was addressed in kv_cash_mem.\n",
    "  # I also add +1 for outputs of Attention since I assume an implementation akin to Flash Attention forward.\n",
    "  token_atten_mem = (1+3) * spec['dim'] * format_2_byte_factor[model_format] \n",
    "\n",
    "  # We are only interested in bottleneck, although it should be quite small anyway;\n",
    "  # emb_dim and out_dim equal dim.\n",
    "  activations_bottleneck_mem = max(FF_bottleneck_mem, token_atten_mem)\n",
    "\n",
    "  # bytes to store the model\n",
    "  model_mem = spec['params'] * format_2_byte_factor[model_format]\n",
    "\n",
    "  return gpu_mem >= model_mem + activations_bottleneck_mem + kv_cash_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b98443-3e73-4d1c-b822-f9c5af3b7cc5",
   "metadata": {},
   "source": [
    "## GPU specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe95050-1a41-4cb6-9a32-06dddec8c596",
   "metadata": {},
   "source": [
    "A quote from NVIDIA, https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80774d3-f642-42a7-b818-d4d57dee9d23",
   "metadata": {},
   "source": [
    "\"Ampere architecture introduces new support for TF32, enabling AI training to use tensor cores by default with no effort on the user’s part. Non-tensor operations continue to use the FP32 datapath, while TF32 tensor cores read FP32 data and use the same range as FP32 with reduced internal precision...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2312ce-285a-4da6-982c-19e8acc2f014",
   "metadata": {},
   "source": [
    "I concentrate our attention on TF format, since the vast majority of compute is occupied by matrix (or matrix by vector) multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15332b-39fc-4836-b9d6-f045c52e84f0",
   "metadata": {},
   "source": [
    "For int4 on V100 it seems like NVIDIA (and everybody) literally doesn't know. For H100 as well."
   ]
  },
  {
   "attachments": {
    "aa7b0ae5-45f7-4d35-8e30-a5671c10f860.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3eacb6d7-98d1-4725-a348-f39639941413",
   "metadata": {},
   "source": [
    "![image.png](attachment:aa7b0ae5-45f7-4d35-8e30-a5671c10f860.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e0f5a-d8cf-4e2b-a71d-e5215ab43df9",
   "metadata": {},
   "source": [
    "Also there are no Tensor cores for int4 on V100 and H100. So for H100 I will assume that the fastest way would be to\n",
    "cast it to int8 and use tensor cores. And I will also assume that such a casting is fast. For V100 I will use a bit of information from NVIDIA, 2019:\n",
    "\"INT4 Precision Can Bring an Additional 59% Speedup Compared to INT8\". Since there are no Tensor Cores on V100 for int8 either, that seems fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3903e35d-34bb-401f-bca9-b9fa61ed1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_specs = {\n",
    "  'V100': {\n",
    "    'HBM': 32e9, # in bytes\n",
    "    'bandwidth': 0.9e12, # per sec\n",
    "    'fp32': 125e12, # FLOPS for that data format on tensors. Is specified as \"Tensor Performance\" in NVIDIA guide.\n",
    "    'fp16': 130e12, # It's all weird with V100, can't find official info.\n",
    "    'int8': 62.8e12, # TOPS, less than fp32 since there are no tensor cores for int8\n",
    "    'int4': 100e12, # see assumption above\n",
    "  },\n",
    "  'A100': {\n",
    "    'HBM': 80e9,\n",
    "    'bandwidth': 1.935e12,\n",
    "    'fp32': 156e12, # FLOPS for that data format. It in fact corrresponds to TF32 tensor cores.\n",
    "    'fp16': 312e12,\n",
    "    'int8': 624e12, # TOPS\n",
    "    'int4': 1.248e15,\n",
    "  },\n",
    "  'H100': {\n",
    "    'HBM': 80e9,\n",
    "    'bandwidth': 3.35e12,\n",
    "    'fp32': 494e12,\n",
    "    'fp16': 989e12, \n",
    "    'int8': 1.978e15,\n",
    "    'int4': 1.978e15, # see assuption above\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf973e40-e4c8-4a0e-9f7c-b3fffed49653",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d46d59f-7b1f-4350-b022-9509bb53ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_memory(model_arch: str, model_format: str, KV_cache_format: str, in_len: int, out_len: int):\n",
    "  \"\"\"\n",
    "  Calculates inference memory footprint.\n",
    "\n",
    "  Args:\n",
    "    model_arch: one of ['LLaMA', 'LLaMA2', 'Mistral', 'Mixtral']\n",
    "    model_format: one of ['fp32', 'fp16', 'int8', 'int4']\n",
    "    KV_cache_format: a format of previous key value cache, one of ['fp32', 'fp16', 'int8']\n",
    "    in_len: max context length\n",
    "    out_len: max output length\n",
    "\n",
    "  Returns\n",
    "    int: required HBM memory in bytes\n",
    "  \n",
    "  Since input and output were set apart in the task formulation, \n",
    "  I decided that it would be more appropriate to process context tokens in parallel, unlike how we did in the first task.\n",
    "  I assume Attention through the context tokens is computed the same way as in Flash Attention forward.\n",
    "  \"\"\"\n",
    "  \n",
    "  spec = specs[model_arch]\n",
    "  \n",
    "  assert in_len+out_len <= spec['max_tokens'], 'This model can\\'t handle a text that long'\n",
    "\n",
    "  # bytes to store the model\n",
    "  model_mem = spec['params'] * format_2_byte_factor[model_format]\n",
    "  \n",
    "  # bytes to store kv cache\n",
    "  # see calc_max_length() for more details\n",
    "  kv_cash_mem = 2 * min(spec['sliding_window'], in_len+out_len-1) * format_2_byte_factor[KV_cache_format] * \\\n",
    "                spec['n_kv_heads'] * (spec['dim'] / spec['n_heads']) * spec['n_layers']\n",
    "\n",
    "  # bytes for successive token activations\n",
    "  # see calc_max_length() for more details\n",
    "  gen_FF_bottleneck_mem = (spec['feed_forward_dim'] + spec['dim']) * \\\n",
    "                          format_2_byte_factor[model_format] # spec['dim'] for residual connection\n",
    "  if model_arch == 'Mixtral':\n",
    "    gen_FF_bottleneck_mem *= 2 \n",
    "  gen_token_atten_mem = (1+3) * spec['dim'] * format_2_byte_factor[model_format] \n",
    "  gen_activations_bottleneck_mem = max(gen_FF_bottleneck_mem, gen_token_atten_mem)\n",
    "\n",
    "  # bytes for context activations\n",
    "  # see calc_max_length() for more details\n",
    "  con_FF_bottleneck_mem = (spec['feed_forward_dim'] + spec['dim']) * format_2_byte_factor[model_format] * in_len\n",
    "  if model_arch == 'Mixtral':\n",
    "    con_FF_bottleneck_mem *= 2 \n",
    "  # I assume that Flash Attention statistics l, m are kept in local memory. \n",
    "  # Otherwize we should add 2*in_len*format to the memory footprint, \n",
    "  # which is negligible anyway.\n",
    "  # As usual, objects that arise during intermediate computations are assumed to be kept in local memory, \n",
    "  # in a Fused Kernel fashion.\n",
    "  # See calc_max_length() for more details.\n",
    "  con_token_atten_mem = (1+3) * spec['dim'] * in_len * format_2_byte_factor[model_format] \n",
    "  con_activations_bottleneck_mem = max(con_FF_bottleneck_mem, con_token_atten_mem)\n",
    "\n",
    "  return model_mem + max(kv_cash_mem + gen_activations_bottleneck_mem, con_activations_bottleneck_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b16fa277-4d8d-43c2-9de8-aa3121acc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_times(gpu_name: str, model_arch: str, model_format: str, KV_cache_format: str, in_len: int, out_len: int):\n",
    "  \"\"\"\n",
    "  Calculates \n",
    "   - context processing time (including HBM transfer),\n",
    "   - token generation latency when using kv cash and having context of length in_len \n",
    "     (a bit weird since we don't use out_len here, but no big deal),\n",
    "   - approximate ratio between Attention and FF FLOPs\n",
    "     (as a proxy to Atten and FF operation times: \n",
    "     '...времени работы между операциями attention'а (зависит квадратично от входа) и остальными операциями'). \n",
    "     The reasons why this proxy seems appropriate to me are the following:\n",
    "       1) the vast majority of heavy operations of any heavy layer are matrix multiplications, \n",
    "          which are performed by the same cores in GPU;\n",
    "       2) an assumption that we have a full parallelization and 100% GPU loading.\n",
    "     Note that here HBM memory transfer is not accounted for (as suggested by the task formulation),\n",
    "     although it might contribute significantly to the whole layer latency.\n",
    "\n",
    "  Assumptions:\n",
    "    - 100% GPU utilisation during Atten and FF layers computation.\n",
    "    - Activation functions, Rotary Embeddings and Normalizations are computationaly negligible -- \n",
    "      linear in context length and in hidden dim, \n",
    "      while matrix mul are linear in context length and quadratic in hidden dim. \n",
    "      Therefore they will not be accounted for.\n",
    "    - I honestly don't see any info on HBM latency, \n",
    "      so I just presuppose that model is big enough and intra-level kernels are fused marvelously. \n",
    "      And compute latency using GPU throughput values \n",
    "      (as layer_memory/throughput).\n",
    "      \n",
    "  Args:\n",
    "    gpu_name: one of ['V100', 'A100', 'H100']\n",
    "    args similar to args of inference_memory()\n",
    "\n",
    "  Returns:\n",
    "    Context processing time in seconds, \n",
    "    gen_latency in seconds for a context of length in_len,\n",
    "    Atten_FLOPs/FF_FLOPs\n",
    "  \"\"\"\n",
    "  \n",
    "  spec = specs[model_arch]\n",
    "  gpu_spec = gpu_specs['gpu_name']\n",
    "\n",
    "  assert in_len+out_len <= spec['max_tokens'], 'This model can\\'t handle a text that long'\n",
    "\n",
    "  # Due to fancy activations of llama and Mistral we fave factor 3 instead of 2 here.\n",
    "  # The second factor represents our vision of multiplying matrix by vector in 2 * n*d operations (mul then sum).\n",
    "  con_FF_FLOPs = 3 * 2 * in_len * spec['feed_forward_dim'] * spec['dim'] * spec['n_layers']\n",
    "  if model_arch == 'Mixtral':\n",
    "    con_FF_FLOPs *= 2\n",
    "\n",
    "  # For details see Appendix C in Flash Attention paper https://arxiv.org/abs/2205.14135\n",
    "  # I assume real factors (2 * 2) instead of big-O notation. The first 2 stands for mul then sum in matmul.\n",
    "  # The second factor 2 stands for two mat muls -- QK and PV.\n",
    "  con_Atten_inner_FLOPs = 2 * 2 * in_len**2 * spec['dim']  * spec['n_layers']\n",
    "  # approximate number of FLOPs to get q,k,v for all heads\n",
    "  con_qkv_FLOPs = 2 * 3 * in_len * spec['dim']**2 * spec['n_layers']\n",
    "  con_Atten_FLOPs = con_Atten_inner_FLOPs + con_qkv_FLOPs\n",
    "\n",
    "  HBM_model_transfer = spec['params'] * format_2_byte_factor[model_format] / gpu_spec['bandwidth']\n",
    "\n",
    "  # Now moving to activations transfer:\n",
    "  con_FF_bottleneck_mem = (spec['feed_forward_dim'] + spec['dim']) * format_2_byte_factor[model_format] * in_len\n",
    "  if model_arch == 'Mixtral':\n",
    "    con_FF_bottleneck_mem *= 2 \n",
    "  # See inference_memory() for comments\n",
    "  con_token_atten_mem = (1+3) * spec['dim'] * in_len * format_2_byte_factor[model_format] \n",
    "  con_activations_bottleneck_mem = max(con_FF_bottleneck_mem, con_token_atten_mem)\n",
    "  \n",
    "  # approximately that\n",
    "  HBM_activations_transfer = (con_FF_bottleneck_mem+con_token_atten_mem) * spec['n_layers'] / gpu_spec['bandwidth']\n",
    "\n",
    "  # Context processing time. kv cache format conversion time is considered negligible.\n",
    "  con_proc_time = HBM_model_transfer + (con_Atten_FLOPs+con_FF_FLOPs)/gpu_spec[model_format]\n",
    "\n",
    "  # Now moving to token generation latency\n",
    "\n",
    "  # Analogously to context processing\n",
    "  gen_FF_FLOPs = 3 * 2 * spec['feed_forward_dim'] * spec['dim'] * spec['n_layers']\n",
    "  if model_arch == 'Mixtral':\n",
    "    gen_FF_FLOPs *= 2\n",
    "\n",
    "  # operations shrink in Q along N-dimention\n",
    "  gen_Atten_inner_FLOPs = 2 * 2 * in_len**1 * spec['dim']  * spec['n_layers']\n",
    "  gen_qkv_FLOPs = 2 * 3 * spec['dim']**2 * spec['n_layers']\n",
    "\n",
    "  kv_cash_mem = 2 * min(spec['sliding_window'], in_len+out_len-1) * format_2_byte_factor[KV_cache_format] * \\\n",
    "                spec['n_kv_heads'] * (spec['dim'] / spec['n_heads']) * spec['n_layers']\n",
    "  HBM_kv_transfer = kv_cash_mem / gpu_spec['bandwidth']\n",
    "\n",
    "  # Here I assume that token activations are kept in local memory (cache) or simply they just are lightweight\n",
    "  gen_latency = HBM_model_transfer + HBM_kv_transfer + HBM_activations_transfer + \\\n",
    "                (gen_qkv_FLOPs+gen_FF_FLOPs)/gpu_spec[model_format] + gen_Atten_inner_FLOPs/gpu_spec[KV_cache_format]\n",
    "\n",
    "  return con_proc_time, gen_latency, con_Atten_FLOPs/con_FF_FLOPs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
