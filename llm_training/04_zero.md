# DeepSpeed
 DeepSpeed - библиотека с открытым исходным кодом, разработанная компанией Microsoft для оптимизации обучения больших моделей. Основным ее компонентом является Zero Redundancy Optimizer (ZeRO) - технология оптимизации памяти для крупномасштабного распределенного глубокого обучения.
 
<img src="https://github.com/RuinedOustrich/-/assets/88096652/8e9b7c76-28ec-4f1d-a6b4-0ba6428524b2" width="500">\
сравнение методов оптимизации обучения t5-large на двух Titan RTX 24 гб

## Преимущества DeepSpeed Zero ##

- Позволяет разместить модели большего размера на графическом процессоре
- Увеличивает скорость обучения 
- Для использования необходимо минимальное количество кода
- Совместим с различными архитектурами, что позволяет запустить новый цикл обучения за минимальное время после изменения модели 

## Как работает ##

Подход ZeRO заключается в равномерном распределении параметров, градиентов и состояний оптимизатора по всем GPU и выделении каждому только одного раздела. Во время выполнения каждый графический процессор обрабатывает данные каждого уровня, а в конце шага обучения запрашивает у остальных GPU недостающую информацию.

<img src="https://github.com/RuinedOustrich/-/assets/88096652/a73b2e4b-846b-4823-b559-fe6c2d968e4b" width="700">

ZeRO состоит из трех этапов.
### ZeRO Stage 1 - Optimizer state partitioning
Идея: Состояния оптимизатора делятся на N равных частей, что каждый процесс обновляет и хранит только соответствующий ему раздел состояний.

<img src="https://github.com/RuinedOustrich/-/assets/88096652/af004231-b5ff-49d4-9b11-907a0820d4d3" width="400">

Реализация: Каждому процессу выделяется раздел состояний оптимизатора. После вычисления градиента процессор выполняет операцию reduce-scatter для нахождения усредненного градиента. Затем процесс считает обновленные веса, соответствующие той части параметров оптимизатора, которая относится к нему. В конце шага обучения производится передача обновленных параметров всем остальным процессам(allgather).

<img src="https://github.com/RuinedOustrich/-/assets/88096652/2f83c09d-8b23-4f1f-9b13-ffdba04b6bcb" width="500">
<img src="https://github.com/RuinedOustrich/-/assets/88096652/30794b88-c73a-4cae-bcd8-0a0f42328891" width="500">

**Zero 1 позволяет сократить использование памяти в 4 раза по сравнению с обычным DDP при том же объеме обмена данными.**

### ZeRO Stage 2 - Gradient partitioning

Идея: Между GPU, разделяются состояния оптимизатора и соответствующие им градиенты.

<img src="https://github.com/RuinedOustrich/-/assets/88096652/609bfa00-fe87-4a9c-b3f4-086d8b0ce060" width="400">

Реализация: Поскольку каждый градиент каждого слоя становится доступным во время обратного шага градиентного спуска, мы усредняем(reduce-scatter) их только в процессе, ответственном за обновление соответствующих параметров. После этого нам больше не нужны градиенты, и их память может быть освобождена.

**Zero 2 позволяет сократить использование памяти в 8 раз по сравнению с обычным DDP при том же объеме обмена данными**

### ZeRO Stage 3 - Parameter partitioning

Здесь между GPU, помимо состояний оптимизатора и градиентов разделяются также параметры модели

Рассмотрим эту простую модель с 3 слоями, где каждый слой имеет 3 параметра:
La | Lb | Lc
---|----|---
a0 | b0 | c0
a1 | b1 | c1
a2 | b2 | c2

Если у нас есть 3 графических процессора, Zero-3 разбивает модель на 3 графических процессора следующим образом:

GPU0:
La | Lb | Lc
---|----|---
a0 | b0 | c0

GPU1:
La | Lb | Lc
---|----|---
a1 | b1 | c1

GPU2:
La | Lb | Lc
---|----|---
a2 | b2 | c2

Теперь каждый из этих графических процессоров получит обычный мини-батч, как это работает в DP:

x0 => GPU0\
x1 => GPU1\
x2 => GPU2

Такой подход позволяет сократить использование памяти по сравнению с обычным DDP в (степень распараллеливания) раз, например, разделение на 64 графических процессора приведет к сокращению объема памяти в 64 раза. При этом в 1.5 раз повышается объем обмена данными. 

## Несколько доступных модификаций

- Zero-R -  улучшает ZeRO-DP, уделяя особое внимание потреблению памяти при активациях и управляя фрагментацией памяти
- Zero- Offload - метод оптимизации, который позволяет разгрузить оптимизатор и вычисления с графических процессоров на главный процессор
- Zero++ - усовершенствование ZeRO-3. Ключевые улучшения:
  1. Квантованные веса 
  2. Иерархическое секционирование 
  3. Квантованные градиенты

## Пример использования DeepSpeed Zero в коде

<img src="https://github.com/RuinedOustrich/-/assets/88096652/eb5747c3-be02-46ca-8b1c-b6b0172e0b1b" width="500">
